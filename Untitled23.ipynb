{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§ª Python Implementation (GAN for Image Generation):\n"
      ],
      "metadata": {
        "id": "k-IyxEk1C0I_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ywuzx0ULCvgd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 1024)\n",
        "        self.fc4 = nn.Linear(1024, 28 * 28)  # 28x28 image size (MNIST)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()  # For output to be in range [-1, 1]\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = self.relu(self.fc1(z))\n",
        "        z = self.relu(self.fc2(z))\n",
        "        z = self.relu(self.fc3(z))\n",
        "        z = self.tanh(self.fc4(z))\n",
        "        return z.view(-1, 1, 28, 28)  # Reshape to image dimensions\n",
        ""
      ],
      "metadata": {
        "id": "x7WKtvvbC3wL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define the Discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 1)  # Output single value: real or fake\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "Bxhppt50C-J0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Initialize models, loss function, and optimizers\n",
        "z_dim = 100  # Latent vector dimension (noise)\n",
        "generator = Generator(z_dim)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Binary cross-entropy loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers for both generator and discriminator\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "EUMPWWySDBAR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngogBX1nDDfa",
        "outputId": "7c22040d-8ec5-4b4d-f74a-c54770a15a0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 54.6MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.54MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 12.4MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 4.55MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Training loop for GAN\n",
        "!pip install torchvision\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(train_loader):\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Create labels for real and fake data\n",
        "        real_labels = torch.ones(batch_size, 1)  # Real data labels are 1\n",
        "        fake_labels = torch.zeros(batch_size, 1)  # Fake data labels are 0\n",
        "\n",
        "        # Train the Discriminator: Maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Train on real images\n",
        "        outputs = discriminator(real_images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        d_loss_real.backward()\n",
        "\n",
        "        # Train on fake images\n",
        "        z = torch.randn(batch_size, z_dim)  # Random noise for generator input\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images.detach())  # Detach to avoid training generator\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        # Update the discriminator\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train the Generator: Minimize log(1 - D(G(z))) = Maximize log(D(G(z)))\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Try to fool the discriminator with fake images\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)  # We want fake images to be classified as real\n",
        "        g_loss.backward()\n",
        "\n",
        "        # Update the generator\n",
        "        optimizer_g.step()\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
        "\n",
        "    # Generate and save sample images\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            fake_images = generator(torch.randn(64, z_dim)).detach().cpu()\n",
        "            grid_img = torchvision.utils.make_grid(fake_images, nrow=8, normalize=True)\n",
        "            plt.imshow(grid_img.permute(1, 2, 0))\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "D8MUMeg9DF5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ryTvyNODOez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}